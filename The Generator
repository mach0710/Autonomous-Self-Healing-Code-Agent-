from langchain_core.prompts import ChatPromptTemplate
from typing import TypedDict, Optional

class AgentState(TypedDict):
    requirement: str      # The user's request
    code: str             # The current python code
    tests: str            # The unit tests
    error: Optional[str]  # Capture stderr if failed
    output: Optional[str] # Capture stdout
    iterations: int       # Iteration counter
    success: bool         # Did it pass?

def write_code_node(state: AgentState):
    print(f"--- GENERATING CODE (Attempt {state['iterations']}) ---")

    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are an expert Python programmer. Return ONLY Python code. No markdown, no explanations."),
        ("user", "Write a Python function to solve this: {requirement}")
    ])
    chain = prompt | llm
    result = chain.invoke({"requirement": state['requirement']})

    # Simple regex to strip markdown blocks if Llama-3 adds them
    clean_code = result.content.replace("```python", "").replace("```", "").strip()

    return {"code": clean_code, "iterations": state['iterations'] + 1}
